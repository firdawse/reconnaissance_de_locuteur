{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "717c3241",
   "metadata": {},
   "source": [
    "## Extraction des mfcss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8ad960f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1.wav\n",
      "F11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F3 .wav\n",
      "F4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F6.wav\n",
      "F7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F8.wav\n",
      "F9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import python_speech_features\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import pickle\n",
    "# Définition des paramètres MFCC\n",
    "numcep = 13\n",
    "nfilt = 26\n",
    "nfft = 512\n",
    "lowfreq = 0\n",
    "highfreq = None\n",
    "preemph = 0.97\n",
    "ceplifter = 22\n",
    "winlen = 0.025\n",
    "winstep = 0.01\n",
    "\n",
    "\n",
    "lang_dir = 'dataset/Train/F/'\n",
    "for filename in os.listdir(lang_dir):\n",
    "    #print(filename)\n",
    "    (rate, sig) = wav.read(lang_dir+filename)\n",
    "    mfcc_feat = python_speech_features.mfcc(sig, rate, winlen=0.025, winstep=0.01, numcep=13, nfilt=26, lowfreq=0, highfreq=None, preemph=0.97, ceplifter=22, appendEnergy=False)\n",
    "    \n",
    "    n_components = 2  # number of GMM components\n",
    "    gmm = GaussianMixture(n_components=n_components)  # create GMM object\n",
    "    gmm.fit(mfcc_feat)  # fit GMM model to data\n",
    "    log_prob = gmm.score_samples(mfcc_feat)\n",
    "    # Select frames with log-likelihood above a threshold\n",
    "    threshold = np.percentile(log_prob, 10)  # adjust percentile to select more or fewer frames\n",
    "    non_silent = mfcc_feat[log_prob >= threshold]\n",
    "    \n",
    "    root, ext = os.path.splitext(filename)\n",
    "    with open('mfcc/train/F/'+root+'.mfcc', 'wb') as f:\n",
    "        pickle.dump(non_silent, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "439f5d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2.wav\n",
      "H4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (2400) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H9.wav\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "lang_dir = 'dataset/Train/H/'\n",
    "for filename in os.listdir(lang_dir):\n",
    "    #print(filename)\n",
    "    (rate, sig) = wav.read(lang_dir+filename)\n",
    "    mfcc_feat = python_speech_features.mfcc(sig, rate, winlen=0.025, winstep=0.01, numcep=13, nfilt=26, lowfreq=0, highfreq=None, preemph=0.97, ceplifter=22, appendEnergy=False)\n",
    "    n_components = 2  # number of GMM components\n",
    "    gmm = GaussianMixture(n_components=n_components)  # create GMM object\n",
    "    gmm.fit(mfcc_feat)  # fit GMM model to data\n",
    "    log_prob = gmm.score_samples(mfcc_feat)\n",
    "    # Select frames with log-likelihood above a threshold\n",
    "    threshold = np.percentile(log_prob, 10)  # adjust percentile to select more or fewer frames\n",
    "    non_silent = mfcc_feat[log_prob >= threshold]\n",
    "    root, ext = os.path.splitext(filename)\n",
    "    with open('mfcc/train/H/'+root+'.mfcc', 'wb') as f:\n",
    "        pickle.dump(non_silent, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "8ea4545f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (2400) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lang_dir = 'dataset/Test/H/'\n",
    "for filename in os.listdir(lang_dir):\n",
    "    (rate, sig) = wav.read(lang_dir+filename)\n",
    "    mfcc_feat = python_speech_features.mfcc(sig, rate, winlen=0.025, winstep=0.01, numcep=13, nfilt=26, lowfreq=0, highfreq=None, preemph=0.97, ceplifter=22, appendEnergy=False)\n",
    "    n_components = 2  # number of GMM components\n",
    "    gmm = GaussianMixture(n_components=n_components)  # create GMM object\n",
    "    gmm.fit(mfcc_feat)  # fit GMM model to data\n",
    "    log_prob = gmm.score_samples(mfcc_feat)\n",
    "    # Select frames with log-likelihood above a threshold\n",
    "    threshold = np.percentile(log_prob, 10)  # adjust percentile to select more or fewer frames\n",
    "    non_silent = mfcc_feat[log_prob >= threshold]\n",
    "    root, ext = os.path.splitext(filename)\n",
    "    with open('mfcc/test/H/'+root+'.mfcc', 'wb') as f:\n",
    "        pickle.dump(non_silent, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f1ae082b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    }
   ],
   "source": [
    "lang_dir = 'dataset/Test/F/'\n",
    "for filename in os.listdir(lang_dir):\n",
    "    (rate, sig) = wav.read(lang_dir+filename)\n",
    "    mfcc_feat = python_speech_features.mfcc(sig, rate, winlen=0.025, winstep=0.01, numcep=13, nfilt=26, lowfreq=0, highfreq=None, preemph=0.97, ceplifter=22, appendEnergy=False)\n",
    "    n_components = 2  # number of GMM components\n",
    "    gmm = GaussianMixture(n_components=n_components)  # create GMM object\n",
    "    gmm.fit(mfcc_feat)  # fit GMM model to data\n",
    "    log_prob = gmm.score_samples(mfcc_feat)\n",
    "    # Select frames with log-likelihood above a threshold\n",
    "    threshold = np.percentile(log_prob, 10)  # adjust percentile to select more or fewer frames\n",
    "    non_silent = mfcc_feat[log_prob >= threshold]\n",
    "    root, ext = os.path.splitext(filename)\n",
    "    with open('mfcc/test/F/'+root+'.mfcc', 'wb') as f:\n",
    "        pickle.dump(non_silent, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e66828",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd4a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "def segment(filename,nbr,lang_dir):\n",
    "    with open(lang_dir+filename, 'rb') as f:\n",
    "        file = pickle.load(f)\n",
    "    num_frames, num_coefficients = file.shape\n",
    "    # Calculate the number of frames per segment\n",
    "    root, ext = os.path.splitext(filename)\n",
    "    frames_per_segment = num_frames // nbr\n",
    "    for i in range(nbr):\n",
    "        start_frame = i * frames_per_segment\n",
    "        end_frame = (i + 1) * frames_per_segment\n",
    "        segment = file[start_frame:end_frame, :]\n",
    "        if('/F/'in lang_dir):\n",
    "            with open('Segments/'+str(int(60/nbr))+'/F/'+root+'.'+str(int(60/nbr))+\".\"+str(i+1)+'.mfcc', 'wb') as f:\n",
    "                pickle.dump(segment, f)\n",
    "        else :\n",
    "            with open('Segments/'+str(int(60/nbr))+'/H/'+root+'.'+str(int(60/nbr))+\".\"+str(i+1)+'.mfcc', 'wb') as f:\n",
    "                pickle.dump(segment, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "fd69e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_dir='mfcc/test/F/'\n",
    "for filename in os.listdir(lang_dir):\n",
    "    segment(filename,20,lang_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "954400da",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_dir='mfcc/test/F/'\n",
    "for filename in os.listdir(lang_dir):\n",
    "    segment(filename,6,lang_dir)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f8411f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_dir='mfcc/test/F/'\n",
    "for filename in os.listdir(lang_dir):\n",
    "    segment(filename,4,lang_dir)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe3fc62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_dir='mfcc/test/F/'\n",
    "for filename in os.listdir(lang_dir):\n",
    "    segment(filename,2,lang_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "9851f4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_dir='mfcc/test/H/'\n",
    "for filename in os.listdir(lang_dir):\n",
    "    segment(filename,20,lang_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "102ac875",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_dir='mfcc/test/H/'\n",
    "import pickle\n",
    "for filename in os.listdir(lang_dir):\n",
    "    segment(filename,6,lang_dir)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24bce932",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_dir='mfcc/test/H/'\n",
    "for filename in os.listdir(lang_dir):\n",
    "    segment(filename,4,lang_dir)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57545767",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_dir='mfcc/test/H/'\n",
    "for filename in os.listdir(lang_dir):\n",
    "    segment(filename,2,lang_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c053acc0",
   "metadata": {},
   "source": [
    "## Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "53e06823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(lang_dir,nbr):\n",
    "    for filename in os.listdir(lang_dir):\n",
    "        root, ext = os.path.splitext(filename)\n",
    "        with open(lang_dir+filename, 'rb') as f:\n",
    "            file = pickle.load(f)\n",
    "        gmm = GaussianMixture(n_components=nbr, covariance_type='full')\n",
    "        gmm.fit(np.vstack(file))\n",
    "        if('/F/'in lang_dir):\n",
    "            with open('gmm/'+'/F/'+str(nbr)+'/'+root+'.'+str(nbr)+'.gmm', 'wb') as f:\n",
    "                pickle.dump(gmm, f)\n",
    "        else :\n",
    "            with open('gmm/'+'/H/'+str(nbr)+'/'+root+'.'+str(nbr)+'.gmm', 'wb') as f:\n",
    "                pickle.dump(gmm, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "06450835",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_dir = 'mfcc/train/H/'\n",
    "model(lang_dir,128)\n",
    "model(lang_dir,256)    \n",
    "model(lang_dir,512)\n",
    "model(lang_dir,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "69068f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_dir = 'mfcc/train/F/'\n",
    "model(lang_dir,128)\n",
    "model(lang_dir,256)    \n",
    "model(lang_dir,512)\n",
    "model(lang_dir,1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4033d27d",
   "metadata": {},
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3692057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(file,gmm):\n",
    "    log_likelihood = gmm.score_samples(file)\n",
    "    mean =  np.mean(log_likelihood)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "391e1308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGmm(path,nbr):\n",
    "    gmms=[]\n",
    "    if('/F/'in path):\n",
    "        path2 = 'gmm/F/'+str(nbr)\n",
    "    else :\n",
    "        path2 = 'gmm/H/'+str(nbr)\n",
    "    \n",
    "    roots =[]\n",
    "    for filename in os.listdir(path2):\n",
    "        root, ext = os.path.splitext(filename)\n",
    "        with open(path2+'/'+filename, 'rb') as f:\n",
    "            file = pickle.load(f)\n",
    "            gmms.append(file)\n",
    "            roots.append(root)\n",
    "    return gmms,roots    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "e79bfc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gmm_scores(lang_dir,nbr):\n",
    "    gmms,roots = loadGmm(lang_dir,nbr)\n",
    "    models = []\n",
    "    results = []\n",
    "    for filename in os.listdir(lang_dir):\n",
    "        scores =[]\n",
    "        names = []\n",
    "        root, ext = os.path.splitext(filename)\n",
    "        with open(lang_dir+filename, 'rb') as f:\n",
    "            file = pickle.load(f)\n",
    "        for i in range(len(gmms)):\n",
    "            root, ext = os.path.splitext(filename)\n",
    "            scores.append(score(file,gmms[i]))\n",
    "            results.append({\n",
    "                        'Recording Name': root,\n",
    "                        'Model Name': roots[i],\n",
    "                        'Score': score(file,gmms[i])\n",
    "                    })\n",
    "    df = pd.DataFrame(results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a302af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "lang_dir = 'Segments/3/H/'\n",
    "gmms,roots = loadGmm(lang_dir,128)\n",
    "df = calculate_gmm_scores(lang_dir,128)\n",
    "#calculate_and_store_scores(directory,nbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "5684c663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recording Name</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H1.3.1</td>\n",
       "      <td>H1.128</td>\n",
       "      <td>-50.886092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H1.3.1</td>\n",
       "      <td>H2.128</td>\n",
       "      <td>-454.760850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H1.3.1</td>\n",
       "      <td>H4.128</td>\n",
       "      <td>-549.383008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H1.3.1</td>\n",
       "      <td>H5.128</td>\n",
       "      <td>-590.224754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H1.3.1</td>\n",
       "      <td>H6.128</td>\n",
       "      <td>-257.973788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>H1.3.1</td>\n",
       "      <td>H7.128</td>\n",
       "      <td>-88.847773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>H1.3.1</td>\n",
       "      <td>H8.128</td>\n",
       "      <td>-73.618699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H1.3.1</td>\n",
       "      <td>H9.128</td>\n",
       "      <td>-73.161958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Recording Name Model Name       Score\n",
       "0         H1.3.1     H1.128  -50.886092\n",
       "1         H1.3.1     H2.128 -454.760850\n",
       "2         H1.3.1     H4.128 -549.383008\n",
       "3         H1.3.1     H5.128 -590.224754\n",
       "4         H1.3.1     H6.128 -257.973788\n",
       "5         H1.3.1     H7.128  -88.847773\n",
       "6         H1.3.1     H8.128  -73.618699\n",
       "7         H1.3.1     H9.128  -73.161958"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a409593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_size = 20\n",
    "num_groups = len(df) // group_size\n",
    "\n",
    "max_scores = []\n",
    "for i in range(num_groups):\n",
    "    start_index = i * group_size\n",
    "    end_index = (i + 1) * group_size\n",
    "    group_scores = df['Score'][start_index:end_index]\n",
    "    max_score = group_scores.max()\n",
    "    max_scores.append(max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "407049ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-49.442451629354345,\n",
       " -50.11722268253231,\n",
       " -45.6205295834607,\n",
       " -46.10805484438308]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b1425caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_fichier_excel = 'score_hommes.xlsx'\n",
    "df.to_excel(nom_fichier_excel, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_dir = 'Segments/3/F/'\n",
    "gmms,roots = loadGmm(lang_dir,128)\n",
    "df2 = calculate_gmm_scores(lang_dir,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0091a7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_fichier_excel = 'score_femmes.xlsx'\n",
    "df2.to_excel(nom_fichier_excel, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f317a",
   "metadata": {},
   "source": [
    "## Taux d'erreur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73f670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Error(df,nbr):\n",
    "    score = df[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
